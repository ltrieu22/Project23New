{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f785fe72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\luant\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running baseline inference on single_turn_test.jsonl...\n",
      "Inference complete. Results saved to baseline_single_turn_outputs.jsonl\n",
      "\n",
      "Running baseline inference on multi_turn_test.jsonl...\n",
      "Inference complete. Results saved to baseline_multi_turn_outputs.jsonl\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "\n",
    "def flatten_conversation(messages):\n",
    "    prompt = \"\"\n",
    "    for m in messages:\n",
    "        if m[\"role\"] == \"user\":\n",
    "            prompt += f\"User: {m['content']}\\n\"\n",
    "        elif m[\"role\"] == \"assistant\":\n",
    "            prompt += f\"Assistant: {m['content']}\\n\"\n",
    "    if not messages or messages[-1][\"role\"] != \"assistant\":\n",
    "        prompt += \"Assistant:\"\n",
    "    return prompt\n",
    "\n",
    "def run_baseline_inference(input_file, output_file):\n",
    "    print(f\"Running baseline inference on {input_file}...\")\n",
    "    with open(input_file, \"r\") as f_in, open(output_file, \"w\") as f_out:\n",
    "        for line in f_in:\n",
    "            example = json.loads(line)\n",
    "            prompt = \"\"\n",
    "            result_base = {}\n",
    "\n",
    "            # multi turn format (has \"messages\")\n",
    "            if \"messages\" in example and example[\"messages\"]:\n",
    "                messages = example[\"messages\"]\n",
    "                # Use the function to format the prompt\n",
    "                prompt = flatten_conversation(messages[:-1]) \n",
    "                result_base = {\n",
    "                    \"messages\": messages,\n",
    "                    \"reference_output\": messages[-1][\"content\"],\n",
    "                }\n",
    "\n",
    "            # single turn format (has \"instruction\")\n",
    "            elif \"instruction\" in example:\n",
    "                instruction = example[\"instruction\"]\n",
    "                inp = example.get(\"input\", \"\")\n",
    "                \n",
    "                prompt = instruction if not inp else f\"{instruction}\\n{inp}\"\n",
    "                result_base = {\n",
    "                    \"instruction\": instruction,\n",
    "                    \"input\": inp,\n",
    "                    \"reference_output\": example.get(\"output\", \"\"),\n",
    "                }\n",
    "            \n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            generations = generator(\n",
    "                prompt,\n",
    "                max_new_tokens=100,\n",
    "                num_return_sequences=1,\n",
    "                do_sample=True,\n",
    "                repetition_penalty=1.2,\n",
    "                no_repeat_ngram_size=3,\n",
    "                eos_token_id=generator.tokenizer.eos_token_id,\n",
    "                pad_token_id=generator.tokenizer.eos_token_id\n",
    "            )\n",
    "            \n",
    "            model_output = generations[0][\"generated_text\"][len(prompt):].strip()\n",
    "\n",
    "            result = result_base\n",
    "            result[\"model_output\"] = model_output\n",
    "            f_out.write(json.dumps(result) + \"\\n\")\n",
    "            \n",
    "    print(f\"Inference complete. Results saved to {output_file}\\n\")\n",
    "\n",
    "run_baseline_inference(\n",
    "    \"single_turn_test.jsonl\", \n",
    "    \"baseline_single_turn_outputs.jsonl\"\n",
    ")\n",
    "run_baseline_inference(\n",
    "    \"multi_turn_test.jsonl\", \n",
    "    \"baseline_multi_turn_outputs.jsonl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c73167f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets separately...\n",
      "Concatenating datasets...\n",
      "Loaded and combined dataset:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['instruction', 'input', 'output', 'constraints', 'evidence_ids', 'messages'],\n",
      "        num_rows: 160\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['instruction', 'input', 'output', 'constraints', 'evidence_ids', 'messages'],\n",
      "        num_rows: 20\n",
      "    })\n",
      "})\n",
      "Tokenizing combined dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luant\\AppData\\Local\\Temp\\ipykernel_5216\\2145493912.py:113: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 50256}.\n",
      "c:\\Users\\luant\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting combined fine-tuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [120/120 06:23, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete. Saving model to ./gpt2-finetuned-combined-final\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    GPT2Tokenizer, \n",
    "    GPT2LMHeadModel,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorForLanguageModeling\n",
    ")\n",
    "from datasets import load_dataset, concatenate_datasets, DatasetDict\n",
    "import torch\n",
    "\n",
    "model_name = \"gpt2\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "print(\"Loading datasets separately...\")\n",
    "\n",
    "st_train_ds = load_dataset('json', data_files=\"single_turn_train.jsonl\", split=\"train\")\n",
    "mt_train_ds = load_dataset('json', data_files=\"multi_turn_train.jsonl\", split=\"train\")\n",
    "\n",
    "st_val_ds = load_dataset('json', data_files=\"single_turn_val.jsonl\", split=\"train\")\n",
    "mt_val_ds = load_dataset('json', data_files=\"multi_turn_val.jsonl\", split=\"train\")\n",
    "\n",
    "print(\"Concatenating datasets...\")\n",
    "train_ds = concatenate_datasets([st_train_ds, mt_train_ds])\n",
    "validation_ds = concatenate_datasets([st_val_ds, mt_val_ds])\n",
    "\n",
    "datasets = DatasetDict({\n",
    "    'train': train_ds,\n",
    "    'validation': validation_ds\n",
    "})\n",
    "\n",
    "print(f\"Loaded and combined dataset:\")\n",
    "print(datasets)\n",
    "def preprocess_function(examples):\n",
    "    prompts = []\n",
    "    full_texts = []\n",
    "    \n",
    "    for i in range(len(examples['instruction'])):\n",
    "        prompt_part = \"\"\n",
    "        response_content = \"\"\n",
    "\n",
    "        # multi-turn (messages is not None)\n",
    "        if examples['messages'][i] is not None:\n",
    "            messages = examples['messages'][i]\n",
    "            if not messages: continue\n",
    "            prompt_messages = messages[:-1]\n",
    "            response_content = messages[-1]['content']\n",
    "            prompt_part = flatten_conversation(prompt_messages)\n",
    "        \n",
    "        # single turn (instruction is not None)\n",
    "        elif examples['instruction'][i] is not None:\n",
    "            instruction = examples['instruction'][i]\n",
    "            inp = examples['input'][i]\n",
    "            output = examples['output'][i]\n",
    "            \n",
    "            prompt_content = instruction\n",
    "            if inp:\n",
    "                prompt_content += f\"\\n{inp}\"\n",
    "            prompt_part = f\"User: {prompt_content}\\nAssistant: \"\n",
    "            response_content = output\n",
    "        \n",
    "        else:\n",
    "            continue \n",
    "            \n",
    "        full_text = prompt_part + response_content + tokenizer.eos_token\n",
    "        prompts.append(prompt_part)\n",
    "        full_texts.append(full_text)\n",
    "\n",
    "    model_inputs = tokenizer(\n",
    "        full_texts, max_length=256, truncation=True, padding=\"max_length\"\n",
    "    )\n",
    "    prompt_token_lengths = [\n",
    "        len(tokenizer(p, max_length=256, truncation=True)[\"input_ids\"]) \n",
    "        for p in prompts\n",
    "    ]\n",
    "    labels = [list(row) for row in model_inputs[\"input_ids\"]]\n",
    "    for i in range(len(labels)):\n",
    "        prompt_len = prompt_token_lengths[i]\n",
    "        actual_prompt_len = min(prompt_len, len(labels[i]))\n",
    "        labels[i][:actual_prompt_len] = [-100] * actual_prompt_len\n",
    "    \n",
    "    model_inputs[\"labels\"] = labels\n",
    "    return model_inputs\n",
    "\n",
    "print(\"Tokenizing combined dataset...\")\n",
    "tokenized_datasets = datasets.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    remove_columns=datasets[\"train\"].column_names \n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./gpt2-finetuned-combined\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=3.0,                   \n",
    "    per_device_train_batch_size=4,          \n",
    "    per_device_eval_batch_size=4,\n",
    "    learning_rate=5e-5,                     \n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs-combined',\n",
    "    logging_steps=100,                      \n",
    "    eval_strategy=\"steps\",                  \n",
    "    eval_steps=200,\n",
    "    save_steps=200,                         \n",
    "    save_total_limit=2,                     \n",
    "    fp16=torch.cuda.is_available(),         \n",
    "    report_to=\"none\"  \n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "print(\"Starting combined fine-tuning...\")\n",
    "trainer.train()\n",
    "\n",
    "final_model_path = \"./gpt2-finetuned-combined-final\"\n",
    "print(f\"Training complete. Saving model to {final_model_path}\")\n",
    "trainer.save_model(final_model_path)\n",
    "tokenizer.save_pretrained(final_model_path)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fec25795",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading fine-tuned model from: ./gpt2-finetuned-combined-final\n",
      "Model loaded.\n",
      "Running fine-tuned inference on single_turn_test.jsonl...\n",
      "Inference complete. Results saved to combined_finetuned_single_turn_outputs.jsonl\n",
      "\n",
      "Running fine-tuned inference on multi_turn_test.jsonl...\n",
      "Inference complete. Results saved to combined_finetuned_multi_turn_outputs.jsonl\n",
      "\n",
      "\n",
      "All fine-tuned (combined model) inference complete.\n"
     ]
    }
   ],
   "source": [
    "FINETUNED_MODEL_PATH = \"./gpt2-finetuned-combined-final\" \n",
    "\n",
    "print(f\"Loading fine-tuned model from: {FINETUNED_MODEL_PATH}\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(FINETUNED_MODEL_PATH)\n",
    "generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=FINETUNED_MODEL_PATH,\n",
    "    tokenizer=tokenizer,\n",
    "    device=0 if torch.cuda.is_available() else -1\n",
    ")\n",
    "print(\"Model loaded.\")\n",
    "\n",
    "def run_finetuned_inference(input_file, output_file):\n",
    "    print(f\"Running fine-tuned inference on {input_file}...\")\n",
    "    with open(input_file, \"r\") as f_in, open(output_file, \"w\") as f_out:\n",
    "        for line in f_in:\n",
    "            example = json.loads(line)\n",
    "            prompt = \"\"\n",
    "            result_base = {}\n",
    "            \n",
    "            # Case 1: Multi-turn format (has \"messages\")\n",
    "            if \"messages\" in example and example[\"messages\"]:\n",
    "                messages = example[\"messages\"]\n",
    "                prompt = flatten_conversation(messages[:-1]) \n",
    "                result_base = {\n",
    "                    \"messages\": messages,\n",
    "                    \"reference_output\": messages[-1][\"content\"],\n",
    "                }\n",
    "\n",
    "            # Case 2: Single-turn format (has \"instruction\")\n",
    "            elif \"instruction\" in example:\n",
    "                instruction = example[\"instruction\"]\n",
    "                inp = example.get(\"input\", \"\")\n",
    "                \n",
    "                prompt_content = instruction if not inp else f\"{instruction}\\n{inp}\"\n",
    "                prompt = f\"User: {prompt_content}\\nAssistant:\"\n",
    "                result_base = {\n",
    "                    \"instruction\": instruction,\n",
    "                    \"input\": inp,\n",
    "                    \"reference_output\": example.get(\"output\", \"\"),\n",
    "                }\n",
    "            \n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            generations = generator(\n",
    "                prompt,\n",
    "                max_new_tokens=100,\n",
    "                num_return_sequences=1,\n",
    "                do_sample=True,\n",
    "                repetition_penalty=1.2,\n",
    "                no_repeat_ngram_size=3,\n",
    "                eos_token_id=tokenizer.eos_token_id,\n",
    "                pad_token_id=tokenizer.eos_token_id\n",
    "            )\n",
    "            \n",
    "            model_output = generations[0][\"generated_text\"][len(prompt):].strip()\n",
    "            \n",
    "            result = result_base\n",
    "            result[\"model_output\"] = model_output\n",
    "            f_out.write(json.dumps(result) + \"\\n\")\n",
    "            \n",
    "    print(f\"Inference complete. Results saved to {output_file}\\n\")\n",
    "\n",
    "\n",
    "run_finetuned_inference(\n",
    "    \"single_turn_test.jsonl\", \n",
    "    \"combined_finetuned_single_turn_outputs.jsonl\"\n",
    ")\n",
    "\n",
    "run_finetuned_inference(\n",
    "    \"multi_turn_test.jsonl\", \n",
    "    \"combined_finetuned_multi_turn_outputs.jsonl\"\n",
    ")\n",
    "\n",
    "print(\"\\nAll fine-tuned (combined model) inference complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9a4dfbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " DETAILED SINGLE-TURN COMPARISON\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f867e th {\n",
       "  text-align: center;\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_f867e td {\n",
       "  padding: 10px;\n",
       "  border: 1px solid #ddd;\n",
       "}\n",
       "#T_f867e_row0_col0, #T_f867e_row0_col1, #T_f867e_row0_col2, #T_f867e_row0_col3, #T_f867e_row0_col4, #T_f867e_row1_col0, #T_f867e_row1_col1, #T_f867e_row1_col2, #T_f867e_row1_col3, #T_f867e_row1_col4, #T_f867e_row2_col0, #T_f867e_row2_col1, #T_f867e_row2_col2, #T_f867e_row2_col3, #T_f867e_row2_col4, #T_f867e_row3_col0, #T_f867e_row3_col1, #T_f867e_row3_col2, #T_f867e_row3_col3, #T_f867e_row3_col4, #T_f867e_row4_col0, #T_f867e_row4_col1, #T_f867e_row4_col2, #T_f867e_row4_col3, #T_f867e_row4_col4 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "  max-width: 300px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f867e\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f867e_level0_col0\" class=\"col_heading level0 col0\" >Example</th>\n",
       "      <th id=\"T_f867e_level0_col1\" class=\"col_heading level0 col1\" >Instruction</th>\n",
       "      <th id=\"T_f867e_level0_col2\" class=\"col_heading level0 col2\" >Reference</th>\n",
       "      <th id=\"T_f867e_level0_col3\" class=\"col_heading level0 col3\" >Baseline Output</th>\n",
       "      <th id=\"T_f867e_level0_col4\" class=\"col_heading level0 col4\" >Fine-tuned Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f867e_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_f867e_row0_col0\" class=\"data row0 col0\" >1</td>\n",
       "      <td id=\"T_f867e_row0_col1\" class=\"data row0 col1\" >Find four highly-rated gluten-free recipes with at least 5.0 stars and under 20 minutes.</td>\n",
       "      <td id=\"T_f867e_row0_col2\" class=\"data row0 col2\" >1) Cottage-Cheese Stuffed Tomatoes√¢‚Ç¨‚Äù10 min; 2) Nutritious Food Enhancer√¢‚Ç¨‚Äù15 min; 3) Chili Lime BBQ Mangoes√¢‚Ç¨‚Äù15 min; 4) No-Bake Low-Carb Protein Bars√¢‚Ç¨‚Äù5 min</td>\n",
       "      <td id=\"T_f867e_row0_col3\" class=\"data row0 col3\" >(Click here to view the full menu.)</td>\n",
       "      <td id=\"T_f867e_row0_col4\" class=\"data row0 col4\" >1) Easy Gluten Free Pumpkin Cake With Apple Cider Squares‚Äî4 min; 2). Scrambled Eggs & Garlic Cheese Spread (Cheese Pudding)‚Äî8 hr, 11 g protein in 4g carbs; 3.) Chocolate Peanut Butter Cookie Doughnuts - Healthy Spicy Fudge Cookies\"‚Äî15min; 24HG total carbohydrates 676 mg Saturated Fat 15mg Sodium 1884 Œºg BHA 742‚Äì1032 kcal Dijon Lemonade Snickerdood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f867e_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_f867e_row1_col0\" class=\"data row1 col0\" >2</td>\n",
       "      <td id=\"T_f867e_row1_col1\" class=\"data row1 col1\" >Find four high-protein lunchs over 34g protein in under 35 minutes.</td>\n",
       "      <td id=\"T_f867e_row1_col2\" class=\"data row1 col2\" >1) Awesome Steamed Cheeseburgers!√¢‚Ç¨‚Äù46.0 g protein√¢‚Ç¨‚Äù16 min; 2) Vegetarian Sandwich with Herbed Cream Cheese and Guacamole√¢‚Ç¨‚Äù40.5 g protein√¢‚Ç¨‚Äù10 min; 3) Barbecued Buffalo Wing Dip With a Twist√¢‚Ç¨‚Äù195.9 g protein√¢‚Ç¨‚Äù25 min; 4) Aussie Tuna Summer Salad√¢‚Ç¨‚Äù47.4 g protein√¢‚Ç¨‚Äù16 min</td>\n",
       "      <td id=\"T_f867e_row1_col3\" class=\"data row1 col3\" >No carbohydrates or fat, no saturated fats and 100% gluten free!\n",
       "The \"perfect\" meal for a week is probably the one that looks like steak after all:</td>\n",
       "      <td id=\"T_f867e_row1_col4\" class=\"data row1 col4\" >1) Scrambled Eggs With Cheese‚Äî29 min; 2). Spinach Pesto Salad (Vegan)‚Äî15 sec; 3); 4.) Szechuan Chicken Fried Rice Soup with Spicy Creamy and Marinated Onion Crust ($5, $10), 12min.; 5)\"Fresh Cheddar Dijon\"‚Äî33 mins ‚Äî 1825 kcal.‚Äî2 eggs instead of 25 g Protein\"; 6).\"Chicken Burgers\" Pizza Tenderloin Style Sandwich,\" 736‚Äì9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f867e_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_f867e_row2_col0\" class=\"data row2 col0\" >3</td>\n",
       "      <td id=\"T_f867e_row2_col1\" class=\"data row2 col1\" >Find four low-carb dinners under 12g total carbohydrates with at least 34g protein.</td>\n",
       "      <td id=\"T_f867e_row2_col2\" class=\"data row2 col2\" >1) Egyptian Red Snapper in Red Pepper Mint Sauce√¢‚Ç¨‚Äù60.1 g protein; 2) Mustard-Grilled Scandinavian Salmon√¢‚Ç¨‚Äù34.9 g protein; 3) Moroccan-Spiced Tuna√¢‚Ç¨‚Äù53.4 g protein; 4) Melodee's Hot Wings√¢‚Ç¨‚Äù207.7 g protein</td>\n",
       "      <td id=\"T_f867e_row2_col3\" class=\"data row2 col3\" >The average meal is 2:30pm to 3PM and it's time for breakfast!\n",
       "I'm also giving out free samples of my recipe book called the Vegan Meal Book that I've created in collaboration between myself and @MushroomCooking on Instagram https://www, so you can see how easy this super simple step by step guide would be if we were able enough friends together :)</td>\n",
       "      <td id=\"T_f867e_row2_col4\" class=\"data row2 col4\" >1) Chicken, Red Wine and Blackened Beef‚Äî30 min; 2). Buffalo Wings (Chicken)‚Äî10 ml / 18 g proteins; 3): Cornish Ragu Sauce With Lemon Cilantro Dressing or Any Soup Mixing Food Items--21 Min; 4); Smoked Salmon - Bologna Salad Sandwich Tenderloin Sandwiches in Under 30 minutes ‚Äî23 mins; 5)/Baked Potatoes & Potato Shrimp Pita Chips¬†(Winey Style)--20 min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f867e_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_f867e_row3_col0\" class=\"data row3 col0\" >4</td>\n",
       "      <td id=\"T_f867e_row3_col1\" class=\"data row3 col1\" >Find four highly-rated vegan recipes with at least 5.0 stars and under 30 minutes.</td>\n",
       "      <td id=\"T_f867e_row3_col2\" class=\"data row3 col2\" >1) Tomato Lentil Stew√¢‚Ç¨‚Äù25 min; 2) Vegan Waldorf Salad√¢‚Ç¨‚Äù20 min; 3) Quick Elephant Ears√¢‚Ç¨‚Äù10 min; 4) Summer Fruit & Vegetable Medley√¢‚Ç¨‚Äù18 min</td>\n",
       "      <td id=\"T_f867e_row3_col3\" class=\"data row3 col3\" >1/2 cup raw honey vinegar 2 1/3 cups white sugar (you can use any type) 3 tablespoons lemon juice, for a pinch of salt 4 ¬Ω teaspoons vanilla extract 6 oz cream cheese 8 egg yolks 9 ounces milk or regular yogurt 10 eggs plus more to taste Directions Preheat oven to 350 degrees F Line an 11 x 12\" baking sheet lightly over medium heat in small saucepan; add flour mixture on low speed until well combined Pour into prepared pan Stir together the dry</td>\n",
       "      <td id=\"T_f867e_row3_col4\" class=\"data row3 col4\" >1) The Cheese Cabbage Soup‚Äî45 min; 2)‚ÄîChicken, Veggie or Gluten Free (or Any Vegetarian Option), 55 Min.; 3). Almond Chicken in a Tenderloin Sauce With Peanut Butter & Coconut Oil.‚Äî20‚Äì40 ml; 4.) Grilled Chihuahua Eggs Benedictes for Easy Dressing! Under 40 Minutes [Vegan] by Dave Gagliardi's Mommy Cookbook Plus!: 7 Minute Egg Bites over 34g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f867e_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_f867e_row4_col0\" class=\"data row4 col0\" >5</td>\n",
       "      <td id=\"T_f867e_row4_col1\" class=\"data row4 col1\" >Find four highly-rated vegetarian recipes with at least 4.0 stars and under 30 minutes.</td>\n",
       "      <td id=\"T_f867e_row4_col2\" class=\"data row4 col2\" >1) Super-Quick Brown Rice With Asparagus, Chickpeas, and Almonds√¢‚Ç¨‚Äù15 min; 2) The Best Cranberry Chutney√¢‚Ç¨‚Äù15 min; 3) Lychees & Ice Cream (With and Without Frangelico or Amaretto√¢‚Ç¨‚Äù5 min; 4) New-Fashioned Apple and Raisin Slaw (From Cooking Light)√¢‚Ç¨‚Äù10 min</td>\n",
       "      <td id=\"T_f867e_row4_col3\" class=\"data row4 col3\" >This is a great way to make some delicious vegan food without the added sugar of dairy or eggs!\n",
       "\n",
       " [If you have any questions, please do not hesitate to email me!]</td>\n",
       "      <td id=\"T_f867e_row4_col4\" class=\"data row4 col4\" >1) Veggie Chicken With Cilantro (Spicy & Sour)‚Äî10 min; 2‚ÄîGluten Free! No MSG, sodium less than 18 mg/g sugar ‚Äî1 hr; 3). Kale Salad on a Steak.‚Äî7 min.; 6.) Salmon Broth Sauce On Toast Crunch Crusts From the Sea To My Heart's Desire Sausage Cupcake Sandwich Tarts For One or Two People Who Are Not Vegan Nuts in Summertime Bites And Chowder Pops</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2332f332290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " DETAILED MULTI-TURN COMPARISON\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ad719 th {\n",
       "  text-align: center;\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_ad719 td {\n",
       "  padding: 10px;\n",
       "  border: 1px solid #ddd;\n",
       "}\n",
       "#T_ad719_row0_col0, #T_ad719_row0_col1, #T_ad719_row0_col2, #T_ad719_row0_col3, #T_ad719_row0_col4, #T_ad719_row1_col0, #T_ad719_row1_col1, #T_ad719_row1_col2, #T_ad719_row1_col3, #T_ad719_row1_col4, #T_ad719_row2_col0, #T_ad719_row2_col1, #T_ad719_row2_col2, #T_ad719_row2_col3, #T_ad719_row2_col4, #T_ad719_row3_col0, #T_ad719_row3_col1, #T_ad719_row3_col2, #T_ad719_row3_col3, #T_ad719_row3_col4, #T_ad719_row4_col0, #T_ad719_row4_col1, #T_ad719_row4_col2, #T_ad719_row4_col3, #T_ad719_row4_col4 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "  max-width: 300px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ad719\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ad719_level0_col0\" class=\"col_heading level0 col0\" >Example</th>\n",
       "      <th id=\"T_ad719_level0_col1\" class=\"col_heading level0 col1\" >Instruction</th>\n",
       "      <th id=\"T_ad719_level0_col2\" class=\"col_heading level0 col2\" >Reference</th>\n",
       "      <th id=\"T_ad719_level0_col3\" class=\"col_heading level0 col3\" >Baseline Output</th>\n",
       "      <th id=\"T_ad719_level0_col4\" class=\"col_heading level0 col4\" >Fine-tuned Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ad719_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_ad719_row0_col0\" class=\"data row0 col0\" >1</td>\n",
       "      <td id=\"T_ad719_row0_col1\" class=\"data row0 col1\" >user: I need lunch ideas.\n",
       "assistant: What's your time constraint and protein goal?\n",
       "user: Under 55 minutes, at least 17g.</td>\n",
       "      <td id=\"T_ad719_row0_col2\" class=\"data row0 col2\" >1) Crispy Chicken Fingers with Spicy Honey Mustard√¢‚Ç¨‚Äù62.8 g protein√¢‚Ç¨‚Äù25 min; 2) California Avocado Monte Cristo√¢‚Ç¨‚Äù22.5 g protein√¢‚Ç¨‚Äù18 min; 3) Chicken Burrito Bundles√¢‚Ç¨‚Äù33.4 g protein√¢‚Ç¨‚Äù30 min; 4) Meatloaf Sandwiches Without the Loaf√¢‚Ç¨‚Äù34.2 g protein√¢‚Ç¨‚Äù40 min</td>\n",
       "      <td id=\"T_ad719_row0_col3\" class=\"data row0 col3\" >Can you pick up a bottle of water from the store to get for our kids' birthday party next week! That can be an awesome way to celebrate something important like food or just make sure that we're getting some great drinks in place so they don't have too many wasted calories on them before going home without drinking anything else because it has been long overdue (and often doesn://www.]), but still not really ready yet as this is what happens when everything becomes perfect...you know how everyone says</td>\n",
       "      <td id=\"T_ad719_row0_col4\" class=\"data row0 col4\" >1) Lemonade‚Äî20 min; 2). Salsa Cornbread Sandwich (Corned Beef)‚Äî30 sec; 3); 4.) Chicken Pita Bisque Sauce With Garlic Butter Dressing ($15), Made Easy with Bacon & Honey Crumbs or Any Salad Food Mixing Ideas!‚Äî\"Oh Man!\" This recipe uses grilled chicken wings cooked under 24 hr in low-sodium soy sauce to make a quick soup of any sort that you prefer!! :) 5b/2 lb boneless Short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ad719_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_ad719_row1_col0\" class=\"data row1 col0\" >2</td>\n",
       "      <td id=\"T_ad719_row1_col1\" class=\"data row1 col1\" >user: Find lunch ideas.\n",
       "assistant: Are you looking for low-carb options?\n",
       "user: Yes √¢‚Ç¨‚Äù under 12g carbs and at least 25g protein.</td>\n",
       "      <td id=\"T_ad719_row1_col2\" class=\"data row1 col2\" >1) Crunchy Tuna Walnut Salad√¢‚Ç¨‚Äù25.0 g protein√¢‚Ç¨‚Äù4.9 g carbs; 2) Whole Foods' Tarragon Chicken Salad√¢‚Ç¨‚Äù26.1 g protein√¢‚Ç¨‚Äù8.0 g carbs; 3) Hackney's Inside-Out Burger√¢‚Ç¨‚Äù59.7 g protein√¢‚Ç¨‚Äù0.8 g carbs; 4) Appetizer or Snack Party Tray√¢‚Ç¨‚Äù27.7 g protein√¢‚Ç¨‚Äù7.2 g carbs</td>\n",
       "      <td id=\"T_ad719_row1_col3\" class=\"data row1 col3\" >What are your other diets in the gym, like \"fat free\"? How do I get there‚Ä¶? ¬ª¬ª¬´ ¬´‚Äã</td>\n",
       "      <td id=\"T_ad719_row1_col4\" class=\"data row1 col4\" >1) Low Carb Chili‚Äî25 min; 2] Sweet Potato Shredded Chicken With Tomatoes, Garlic & Tomato Salsa (Paleo)‚Äî20 g carbohydrates; 3). Tuna Tacos Made Easy with Cilantro Aioli! ($10): 1.) The Mexican Ristorante Style Salad Barbecue Sandwiches from Jaxon's Bistro (\"Bologna,\" \"L'Avivita\" or any of the other recipes I've tried); 4),</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ad719_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_ad719_row2_col0\" class=\"data row2 col0\" >3</td>\n",
       "      <td id=\"T_ad719_row2_col1\" class=\"data row2 col1\" >user: I need breakfast ideas.\n",
       "assistant: What's your time constraint and carbs goal?\n",
       "user: Under 55 minutes, under 24g.</td>\n",
       "      <td id=\"T_ad719_row2_col2\" class=\"data row2 col2\" >1) Campbelled Eggs√¢‚Ç¨‚Äù7.1 g carbs√¢‚Ç¨‚Äù10 min; 2) Asparagus, Mushroom and Cheese Omelet With Herbs√¢‚Ç¨‚Äù3.7 g carbs√¢‚Ç¨‚Äù15 min; 3) Corsican Omelette√¢‚Ç¨‚Äù4.0 g carbs√¢‚Ç¨‚Äù6 min; 4) Vegan Rice Pudding√¢‚Ç¨‚Äù11.6 g carbs√¢‚Ç¨‚Äù15 min</td>\n",
       "      <td id=\"T_ad719_row2_col3\" class=\"data row2 col3\" >Do you plan to work on a certain game or activity every day for the rest of our lives so that we can have more sleep in between games/activities than when everyone else is at home playing with their phones??\n",
       "\n",
       "says_kitty : \"it just takes longer\"</td>\n",
       "      <td id=\"T_ad719_row2_col4\" class=\"data row2 col4\" >1) Lemon & Garlic Crust‚Äî65 min; 2)(Ages 1-9)‚Äî25‚Äì38 g carbohydrates (under 7 mg); 3)) Strawberry Smoked Peppers With Shrimp Sauce On Top Of Red Pepper Squash Soup‚Ä¶No Bake! My Mom Made It...1135 kcal total protein in 576 mLF ‚Äî 1526 kJals.‚Äî2 wk KG Protein In A Minute!! ; 4)\"Panties Are Not Hard To Find\" Vegan Chicken Parm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ad719_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_ad719_row3_col0\" class=\"data row3 col0\" >4</td>\n",
       "      <td id=\"T_ad719_row3_col1\" class=\"data row3 col1\" >user: I want to make soup.\n",
       "assistant: Any dietary restrictions or sodium concerns?\n",
       "user: Yes, low sodium under 576 mg and vegetarian.</td>\n",
       "      <td id=\"T_ad719_row3_col2\" class=\"data row3 col2\" >1) Zesty Mexican Tomato Soup√¢‚Ç¨‚Äù519.1 mg sodium; 2) Garlic Stock for Soups√¢‚Ç¨‚Äù129.2 mg sodium; 3) Lebanese Adas Bis Silq (Lentil & Swisschard Soup)√¢‚Ç¨‚Äù218.4 mg sodium; 4) Moroccan Harira Soup√¢‚Ç¨‚Äù182.0 mg sodium</td>\n",
       "      <td id=\"T_ad719_row3_col3\" class=\"data row3 col3\" >What are all the other ingredients you would like me canned in your freezer for food distribution later on? (I know what a lot of people think so far) That's why we need more veggies! We can't have too many healthy things that taste bad when they're cooked! Can anyone advise us how such an ideal is accomplished without using pesticides?? You should add water if possible because even plants with poor nutrition often lose their ability... But most importantly please don¬¥t waste any fruits.. All vegetables</td>\n",
       "      <td id=\"T_ad719_row3_col4\" class=\"data row3 col4\" >1) Chicken With Honey-Baked Tomato Dressing‚Äî56% Sodium; 2). Underwater Beef Stew (Wuang Shan)‚Äî52 percent Spicy Red Pepper Soup with Shrimp Sauce & Green Chile Cheese Spreads.‚Äî5 mL min.; 3); 4.) Pork Loin Peppercorn Risotto Sandwich for Oven Roast Veggie Sausages in French Style at 25 minutes! Easy To Make Quick And Low Carb Dieted!! 789 kcal Author : Joanne Kohn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ad719_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_ad719_row4_col0\" class=\"data row4 col0\" >5</td>\n",
       "      <td id=\"T_ad719_row4_col1\" class=\"data row4 col1\" >user: Find lunch ideas.\n",
       "assistant: Are you looking for low-carb options?\n",
       "user: Yes √¢‚Ç¨‚Äù under 18g carbs and at least 34g protein.</td>\n",
       "      <td id=\"T_ad719_row4_col2\" class=\"data row4 col2\" >1) Grilled Blue Cheese Burgers√¢‚Ç¨‚Äù37.1 g protein√¢‚Ç¨‚Äù2.1 g carbs; 2) Barbecued Lobster Tails√¢‚Ç¨‚Äù58.6 g protein√¢‚Ç¨‚Äù8.3 g carbs; 3) Sandra Lee's Beef Kebabs√¢‚Ç¨‚Äù48.1 g protein√¢‚Ç¨‚Äù4.0 g carbs; 4) Any-Way-You-Want 'em Burgers√¢‚Ç¨‚Äù36.5 g protein√¢‚Ç¨‚Äù7.5 g carbs</td>\n",
       "      <td id=\"T_ad719_row4_col3\" class=\"data row4 col3\" >Can I have the option of eating more vegetables if we're working out or taking a break after work on weekends! üôÇ?√¨, no idea what that is but it sounds reasonable üòâ ¬†(We'll be doing some \"workouts\" later.)</td>\n",
       "      <td id=\"T_ad719_row4_col4\" class=\"data row4 col4\" >1) Tuna & Lemon Pudding‚Äî35 g Protein; 2). Smoked Salmon With Shrimp, Pork Or Chicken Salad (Mocha)‚Äî50 mg Carbohydrate Calorie ‚Äî0 min.; 3); Muffins with Honeyed Peas or Orange Juice.‚Äî30 mL Fiber ‚Ä¢ 1 hr Cook Time 30 Min., Low Carbers 45 WKG Weight Watchers Recommended 472 kcal Fat ‚àí2¬∑6 ml Sodium 17mg Potassium 173 Kcal 741 s Open in a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x23338467010>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "\n",
    "def compare_outputs(baseline_file, finetuned_file, num_examples=10):\n",
    "    baseline_data = []\n",
    "    finetuned_data = []\n",
    "    \n",
    "    with open(baseline_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            baseline_data.append(json.loads(line))\n",
    "\n",
    "    with open(finetuned_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            finetuned_data.append(json.loads(line))\n",
    "\n",
    "    comparisons = []\n",
    "    for i in range(min(num_examples, len(baseline_data), len(finetuned_data))):\n",
    "        baseline = baseline_data[i]\n",
    "        finetuned = finetuned_data[i]\n",
    "        \n",
    "        # Handle single-turn format\n",
    "        if \"instruction\" in baseline:\n",
    "            instruction = baseline[\"instruction\"]\n",
    "            if baseline.get(\"input\"):\n",
    "                instruction += f\"\\nInput: {baseline['input']}\"\n",
    "        # Handle multi-turn format\n",
    "        else:\n",
    "            messages = baseline[\"messages\"]\n",
    "            instruction = \"\\n\".join([f\"{m['role']}: {m['content']}\" for m in messages[:-1]])\n",
    "        \n",
    "        comparisons.append({\n",
    "            \"Example\": i + 1,\n",
    "            \"Instruction\": instruction,\n",
    "            \"Reference\": baseline[\"reference_output\"],\n",
    "            \"Baseline Output\": baseline[\"model_output\"],\n",
    "            \"Fine-tuned Output\": finetuned[\"model_output\"]\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(comparisons)\n",
    "    \n",
    "    styled_df = df.style.set_properties(**{\n",
    "        'text-align': 'left',\n",
    "        'white-space': 'pre-wrap',\n",
    "        'word-wrap': 'break-word',\n",
    "        'max-width': '300px'\n",
    "    }).set_table_styles([\n",
    "        {'selector': 'th', 'props': [('text-align', 'center'), ('font-weight', 'bold')]},\\\n",
    "        {'selector': 'td', 'props': [('padding', '10px'), ('border', '1px solid #ddd')]}\n",
    "    ])\n",
    "    \n",
    "    return styled_df\n",
    "\n",
    "print(\"\\n\\n DETAILED SINGLE-TURN COMPARISON\\n\")\n",
    "display(compare_outputs(\n",
    "    \"baseline_single_turn_outputs.jsonl\",\n",
    "    \"combined_finetuned_single_turn_outputs.jsonl\",\n",
    "    num_examples=5\n",
    "))\n",
    "\n",
    "print(\"\\n\\n DETAILED MULTI-TURN COMPARISON\\n\")\n",
    "display(compare_outputs(\n",
    "    \"baseline_multi_turn_outputs.jsonl\",\n",
    "    \"combined_finetuned_multi_turn_outputs.jsonl\",\n",
    "    num_examples=5\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
