{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b9e51e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in c:\\users\\luant\\documents\\koulu koodit\\nlpprojekti\\project23new\\.venv\\lib\\site-packages (4.57.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\luant\\documents\\koulu koodit\\nlpprojekti\\project23new\\.venv\\lib\\site-packages (from transformers[torch]) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\luant\\documents\\koulu koodit\\nlpprojekti\\project23new\\.venv\\lib\\site-packages (from transformers[torch]) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\luant\\documents\\koulu koodit\\nlpprojekti\\project23new\\.venv\\lib\\site-packages (from transformers[torch]) (2.3.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\luant\\documents\\koulu koodit\\nlpprojekti\\project23new\\.venv\\lib\\site-packages (from transformers[torch]) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\luant\\documents\\koulu koodit\\nlpprojekti\\project23new\\.venv\\lib\\site-packages (from transformers[torch]) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\luant\\documents\\koulu koodit\\nlpprojekti\\project23new\\.venv\\lib\\site-packages (from transformers[torch]) (2025.10.23)\n",
      "Requirement already satisfied: requests in c:\\users\\luant\\documents\\koulu koodit\\nlpprojekti\\project23new\\.venv\\lib\\site-packages (from transformers[torch]) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\luant\\documents\\koulu koodit\\nlpprojekti\\project23new\\.venv\\lib\\site-packages (from transformers[torch]) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\luant\\documents\\koulu koodit\\nlpprojekti\\project23new\\.venv\\lib\\site-packages (from transformers[torch]) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\luant\\documents\\koulu koodit\\nlpprojekti\\project23new\\.venv\\lib\\site-packages (from transformers[torch]) (4.67.1)\n",
      "Requirement already satisfied: torch>=2.2 in c:\\users\\luant\\documents\\koulu koodit\\nlpprojekti\\project23new\\.venv\\lib\\site-packages (from transformers[torch]) (2.10.0a0+rocm7.10.0a20251031)\n",
      "Collecting accelerate>=0.26.0 (from transformers[torch])\n",
      "  Using cached accelerate-1.11.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\luant\\documents\\koulu koodit\\nlpprojekti\\project23new\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers[torch]) (2025.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\luant\\documents\\koulu koodit\\nlpprojekti\\project23new\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers[torch]) (4.15.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\luant\\documents\\koulu koodit\\nlpprojekti\\project23new\\.venv\\lib\\site-packages (from accelerate>=0.26.0->transformers[torch]) (7.1.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\luant\\documents\\koulu koodit\\nlpprojekti\\project23new\\.venv\\lib\\site-packages (from torch>=2.2->transformers[torch]) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\luant\\documents\\koulu koodit\\nlpprojekti\\project23new\\.venv\\lib\\site-packages (from torch>=2.2->transformers[torch]) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\luant\\documents\\koulu koodit\\nlpprojekti\\project23new\\.venv\\lib\\site-packages (from torch>=2.2->transformers[torch]) (3.1.6)\n",
      "Requirement already satisfied: rocm==7.10.0a20251031 in c:\\users\\luant\\documents\\koulu koodit\\nlpprojekti\\project23new\\.venv\\lib\\site-packages (from rocm[libraries]==7.10.0a20251031->torch>=2.2->transformers[torch]) (7.10.0a20251031)\n",
      "Requirement already satisfied: rocm-sdk-core==7.10.0a20251031 in c:\\users\\luant\\documents\\koulu koodit\\nlpprojekti\\project23new\\.venv\\lib\\site-packages (from rocm==7.10.0a20251031->rocm[libraries]==7.10.0a20251031->torch>=2.2->transformers[torch]) (7.10.0a20251031)\n",
      "Requirement already satisfied: rocm-sdk-libraries-gfx110X-all==7.10.0a20251031 in c:\\users\\luant\\documents\\koulu koodit\\nlpprojekti\\project23new\\.venv\\lib\\site-packages (from rocm[libraries]==7.10.0a20251031->torch>=2.2->transformers[torch]) (7.10.0a20251031)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\luant\\documents\\koulu koodit\\nlpprojekti\\project23new\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch>=2.2->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\luant\\documents\\koulu koodit\\nlpprojekti\\project23new\\.venv\\lib\\site-packages (from tqdm>=4.27->transformers[torch]) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\luant\\documents\\koulu koodit\\nlpprojekti\\project23new\\.venv\\lib\\site-packages (from jinja2->torch>=2.2->transformers[torch]) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\luant\\documents\\koulu koodit\\nlpprojekti\\project23new\\.venv\\lib\\site-packages (from requests->transformers[torch]) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\luant\\documents\\koulu koodit\\nlpprojekti\\project23new\\.venv\\lib\\site-packages (from requests->transformers[torch]) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\luant\\documents\\koulu koodit\\nlpprojekti\\project23new\\.venv\\lib\\site-packages (from requests->transformers[torch]) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\luant\\documents\\koulu koodit\\nlpprojekti\\project23new\\.venv\\lib\\site-packages (from requests->transformers[torch]) (2025.10.5)\n",
      "Using cached accelerate-1.11.0-py3-none-any.whl (375 kB)\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-1.11.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f785fe72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\luant\\Documents\\Koulu koodit\\NLPprojekti\\Project23New\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running baseline inference on single_turn_test.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\luant\\Documents\\Koulu koodit\\NLPprojekti\\Project23New\\.venv\\Lib\\site-packages\\transformers\\integrations\\sdpa_attention.py:96: UserWarning: Flash Efficient attention on Current AMD GPU is still experimental. Enable it with TORCH_ROCM_AOTRITON_ENABLE_EXPERIMENTAL=1. (Triggered internally at B:\\src\\torch\\aten\\src\\ATen\\native\\transformers\\hip\\sdp_utils.cpp:317.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "c:\\Users\\luant\\Documents\\Koulu koodit\\NLPprojekti\\Project23New\\.venv\\Lib\\site-packages\\transformers\\integrations\\sdpa_attention.py:96: UserWarning: Mem Efficient attention on Current AMD GPU is still experimental. Enable it with TORCH_ROCM_AOTRITON_ENABLE_EXPERIMENTAL=1. (Triggered internally at B:\\src\\torch\\aten\\src\\ATen\\native\\transformers\\hip\\sdp_utils.cpp:374.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference complete. Results saved to baseline_single_turn_outputs.jsonl\n",
      "\n",
      "Running baseline inference on multi_turn_test.jsonl...\n",
      "Inference complete. Results saved to baseline_multi_turn_outputs.jsonl\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "import torch\n",
    "\n",
    "generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "\n",
    "def flatten_conversation(messages):\n",
    "    prompt = \"\"\n",
    "    for m in messages:\n",
    "        if m[\"role\"] == \"user\":\n",
    "            prompt += f\"User: {m['content']}\\n\"\n",
    "        elif m[\"role\"] == \"assistant\":\n",
    "            prompt += f\"Assistant: {m['content']}\\n\"\n",
    "    if not messages or messages[-1][\"role\"] != \"assistant\":\n",
    "        prompt += \"Assistant:\"\n",
    "    return prompt\n",
    "\n",
    "def run_baseline_inference(input_file, output_file):\n",
    "    print(f\"Running baseline inference on {input_file}...\")\n",
    "    with open(input_file, \"r\", encoding='utf-8') as f_in, open(output_file, \"w\", encoding='utf-8') as f_out:\n",
    "        for line in f_in:\n",
    "            example = json.loads(line)\n",
    "            prompt = \"\"\n",
    "            result_base = {}\n",
    "\n",
    "            # multi turn format (has \"messages\")\n",
    "            if \"messages\" in example and example[\"messages\"]:\n",
    "                messages = example[\"messages\"]\n",
    "                # Use the function to format the prompt\n",
    "                prompt = flatten_conversation(messages[:-1]) \n",
    "                result_base = {\n",
    "                    \"messages\": messages,\n",
    "                    \"reference_output\": messages[-1][\"content\"],\n",
    "                }\n",
    "\n",
    "            # single turn format (has \"instruction\")\n",
    "            elif \"instruction\" in example:\n",
    "                instruction = example[\"instruction\"]\n",
    "                inp = example.get(\"input\", \"\")\n",
    "                \n",
    "                prompt = instruction if not inp else f\"{instruction}\\n{inp}\"\n",
    "                result_base = {\n",
    "                    \"instruction\": instruction,\n",
    "                    \"input\": inp,\n",
    "                    \"reference_output\": example.get(\"output\", \"\"),\n",
    "                }\n",
    "            \n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            if \"constraints\" in example:\n",
    "                result_base[\"constraints\"] = example[\"constraints\"]\n",
    "            if \"evidence_ids\" in example:\n",
    "                result_base[\"evidence_ids\"] = example[\"evidence_ids\"]\n",
    "\n",
    "            generations = generator(\n",
    "                prompt,\n",
    "                max_new_tokens=100,\n",
    "                num_return_sequences=1,\n",
    "                do_sample=True,\n",
    "                repetition_penalty=1.2,\n",
    "                no_repeat_ngram_size=3,\n",
    "                eos_token_id=generator.tokenizer.eos_token_id,\n",
    "                pad_token_id=generator.tokenizer.eos_token_id\n",
    "            )\n",
    "            \n",
    "            model_output = generations[0][\"generated_text\"][len(prompt):].strip()\n",
    "\n",
    "            result = result_base\n",
    "            result[\"model_output\"] = model_output\n",
    "            f_out.write(json.dumps(result, ensure_ascii=False) + \"\\n\")\n",
    "            \n",
    "    print(f\"Inference complete. Results saved to {output_file}\\n\")\n",
    "\n",
    "run_baseline_inference(\n",
    "    \"single_turn_test.jsonl\", \n",
    "    \"baseline_single_turn_outputs.jsonl\"\n",
    ")\n",
    "run_baseline_inference(\n",
    "    \"multi_turn_test.jsonl\", \n",
    "    \"baseline_multi_turn_outputs.jsonl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c73167f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets separately...\n",
      "Concatenating datasets...\n",
      "Loaded and combined dataset:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['instruction', 'input', 'output', 'constraints', 'evidence_ids', 'messages'],\n",
      "        num_rows: 160\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['instruction', 'input', 'output', 'constraints', 'evidence_ids', 'messages'],\n",
      "        num_rows: 20\n",
      "    })\n",
      "})\n",
      "Tokenizing combined dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luant\\AppData\\Local\\Temp\\ipykernel_8100\\3041330073.py:114: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 50256}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting combined fine-tuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [120/120 00:08, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete. Saving model to ./gpt2-finetuned-combined-final\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    GPT2Tokenizer, \n",
    "    GPT2LMHeadModel,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorForLanguageModeling\n",
    ")\n",
    "from datasets import load_dataset, concatenate_datasets, DatasetDict\n",
    "import torch\n",
    "\n",
    "model_name = \"gpt2\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "print(\"Loading datasets separately...\")\n",
    "\n",
    "st_train_ds = load_dataset('json', data_files=\"single_turn_train.jsonl\", split=\"train\")\n",
    "mt_train_ds = load_dataset('json', data_files=\"multi_turn_train.jsonl\", split=\"train\")\n",
    "\n",
    "st_val_ds = load_dataset('json', data_files=\"single_turn_val.jsonl\", split=\"train\")\n",
    "mt_val_ds = load_dataset('json', data_files=\"multi_turn_val.jsonl\", split=\"train\")\n",
    "\n",
    "print(\"Concatenating datasets...\")\n",
    "train_ds = concatenate_datasets([st_train_ds, mt_train_ds])\n",
    "validation_ds = concatenate_datasets([st_val_ds, mt_val_ds])\n",
    "\n",
    "datasets = DatasetDict({\n",
    "    'train': train_ds,\n",
    "    'validation': validation_ds\n",
    "})\n",
    "\n",
    "print(f\"Loaded and combined dataset:\")\n",
    "print(datasets)\n",
    "def preprocess_function(examples):\n",
    "    prompts = []\n",
    "    full_texts = []\n",
    "    \n",
    "    for i in range(len(examples['instruction'])):\n",
    "        prompt_part = \"\"\n",
    "        response_content = \"\"\n",
    "\n",
    "        # multi-turn (messages is not None)\n",
    "        if examples['messages'][i] is not None:\n",
    "            messages = examples['messages'][i]\n",
    "            if not messages: continue\n",
    "            prompt_messages = messages[:-1]\n",
    "            response_content = messages[-1]['content']\n",
    "            prompt_part = flatten_conversation(prompt_messages)\n",
    "        \n",
    "        # single turn (instruction is not None)\n",
    "        elif examples['instruction'][i] is not None:\n",
    "            instruction = examples['instruction'][i]\n",
    "            inp = examples['input'][i] if examples['input'][i] else \"\"\n",
    "            output = examples['output'][i]\n",
    "            \n",
    "            prompt_content = instruction\n",
    "            if inp:\n",
    "                prompt_content += f\"\\n{inp}\"\n",
    "            \n",
    "            prompt_part = f\"User: {prompt_content}\\nAssistant: \"\n",
    "            response_content = output\n",
    "        \n",
    "        else:\n",
    "            continue \n",
    "            \n",
    "        full_text = prompt_part + response_content + tokenizer.eos_token\n",
    "        prompts.append(prompt_part)\n",
    "        full_texts.append(full_text)\n",
    "\n",
    "    model_inputs = tokenizer(\n",
    "        full_texts, max_length=256, truncation=True, padding=\"max_length\"\n",
    "    )\n",
    "    prompt_token_lengths = [\n",
    "        len(tokenizer(p, max_length=256, truncation=True)[\"input_ids\"]) \n",
    "        for p in prompts\n",
    "    ]\n",
    "    labels = [list(row) for row in model_inputs[\"input_ids\"]]\n",
    "    for i in range(len(labels)):\n",
    "        prompt_len = prompt_token_lengths[i]\n",
    "        actual_prompt_len = min(prompt_len, len(labels[i]))\n",
    "        labels[i][:actual_prompt_len] = [-100] * actual_prompt_len\n",
    "    \n",
    "    model_inputs[\"labels\"] = labels\n",
    "    return model_inputs\n",
    "\n",
    "print(\"Tokenizing combined dataset...\")\n",
    "tokenized_datasets = datasets.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    remove_columns=datasets[\"train\"].column_names \n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./gpt2-finetuned-combined\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=3.0,                   \n",
    "    per_device_train_batch_size=4,          \n",
    "    per_device_eval_batch_size=4,\n",
    "    learning_rate=5e-5,                     \n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs-combined',\n",
    "    logging_steps=100,                      \n",
    "    eval_strategy=\"steps\",                  \n",
    "    eval_steps=200,\n",
    "    save_steps=200,                         \n",
    "    save_total_limit=2,                     \n",
    "    fp16=torch.cuda.is_available(),         \n",
    "    report_to=\"none\"  \n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "print(\"Starting combined fine-tuning...\")\n",
    "trainer.train()\n",
    "\n",
    "final_model_path = \"./gpt2-finetuned-combined-final\"\n",
    "print(f\"Training complete. Saving model to {final_model_path}\")\n",
    "trainer.save_model(final_model_path)\n",
    "tokenizer.save_pretrained(final_model_path)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fec25795",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading fine-tuned model from: ./gpt2-finetuned-combined-final\n",
      "Model loaded.\n",
      "Running fine-tuned inference on single_turn_test.jsonl...\n",
      "Inference complete. Results saved to combined_finetuned_single_turn_outputs.jsonl\n",
      "\n",
      "Running fine-tuned inference on multi_turn_test.jsonl...\n",
      "Inference complete. Results saved to combined_finetuned_multi_turn_outputs.jsonl\n",
      "\n",
      "\n",
      "All fine-tuned (combined model) inference complete.\n"
     ]
    }
   ],
   "source": [
    "FINETUNED_MODEL_PATH = \"./gpt2-finetuned-combined-final\" \n",
    "\n",
    "print(f\"Loading fine-tuned model from: {FINETUNED_MODEL_PATH}\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(FINETUNED_MODEL_PATH)\n",
    "generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=FINETUNED_MODEL_PATH,\n",
    "    tokenizer=tokenizer,\n",
    "    device=0 if torch.cuda.is_available() else -1\n",
    ")\n",
    "print(\"Model loaded.\")\n",
    "\n",
    "def run_finetuned_inference(input_file, output_file):\n",
    "    print(f\"Running fine-tuned inference on {input_file}...\")\n",
    "    with open(input_file, \"r\", encoding='utf-8') as f_in, open(output_file, \"w\", encoding='utf-8') as f_out:\n",
    "        for line in f_in:\n",
    "            example = json.loads(line)\n",
    "            prompt = \"\"\n",
    "            result_base = {}\n",
    "            \n",
    "            # Case 1: Multi-turn format (has \"messages\")\n",
    "            if \"messages\" in example and example[\"messages\"]:\n",
    "                messages = example[\"messages\"]\n",
    "                prompt = flatten_conversation(messages[:-1]) \n",
    "                result_base = {\n",
    "                    \"messages\": messages,\n",
    "                    \"reference_output\": messages[-1][\"content\"],\n",
    "                }\n",
    "\n",
    "            # Case 2: Single-turn format (has \"instruction\")\n",
    "            elif \"instruction\" in example:\n",
    "                instruction = example[\"instruction\"]\n",
    "                inp = example.get(\"input\", \"\")\n",
    "                \n",
    "                prompt_content = instruction if not inp else f\"{instruction}\\n{inp}\"\n",
    "                prompt = f\"User: {prompt_content}\\nAssistant:\"\n",
    "                result_base = {\n",
    "                    \"instruction\": instruction,\n",
    "                    \"input\": inp,\n",
    "                    \"reference_output\": example.get(\"output\", \"\"),\n",
    "                }\n",
    "            \n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            if \"constraints\" in example:\n",
    "                result_base[\"constraints\"] = example[\"constraints\"]\n",
    "            if \"evidence_ids\" in example:\n",
    "                result_base[\"evidence_ids\"] = example[\"evidence_ids\"]\n",
    "\n",
    "            generations = generator(\n",
    "                prompt,\n",
    "                max_new_tokens=100,\n",
    "                num_return_sequences=1,\n",
    "                do_sample=True,\n",
    "                repetition_penalty=1.2,\n",
    "                no_repeat_ngram_size=3,\n",
    "                eos_token_id=tokenizer.eos_token_id,\n",
    "                pad_token_id=tokenizer.eos_token_id\n",
    "            )\n",
    "            \n",
    "            model_output = generations[0][\"generated_text\"][len(prompt):].strip()\n",
    "            \n",
    "            result = result_base\n",
    "            result[\"model_output\"] = model_output\n",
    "            f_out.write(json.dumps(result, ensure_ascii=False) + \"\\n\")\n",
    "            \n",
    "    print(f\"Inference complete. Results saved to {output_file}\\n\")\n",
    "\n",
    "\n",
    "run_finetuned_inference(\n",
    "    \"single_turn_test.jsonl\", \n",
    "    \"combined_finetuned_single_turn_outputs.jsonl\"\n",
    ")\n",
    "\n",
    "run_finetuned_inference(\n",
    "    \"multi_turn_test.jsonl\", \n",
    "    \"combined_finetuned_multi_turn_outputs.jsonl\"\n",
    ")\n",
    "\n",
    "print(\"\\nAll fine-tuned (combined model) inference complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9a4dfbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " DETAILED SINGLE-TURN COMPARISON\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_25960 th {\n",
       "  text-align: center;\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_25960 td {\n",
       "  padding: 10px;\n",
       "  border: 1px solid #ddd;\n",
       "}\n",
       "#T_25960_row0_col0, #T_25960_row0_col1, #T_25960_row0_col2, #T_25960_row0_col3, #T_25960_row0_col4, #T_25960_row1_col0, #T_25960_row1_col1, #T_25960_row1_col2, #T_25960_row1_col3, #T_25960_row1_col4, #T_25960_row2_col0, #T_25960_row2_col1, #T_25960_row2_col2, #T_25960_row2_col3, #T_25960_row2_col4, #T_25960_row3_col0, #T_25960_row3_col1, #T_25960_row3_col2, #T_25960_row3_col3, #T_25960_row3_col4, #T_25960_row4_col0, #T_25960_row4_col1, #T_25960_row4_col2, #T_25960_row4_col3, #T_25960_row4_col4 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "  max-width: 300px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_25960\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_25960_level0_col0\" class=\"col_heading level0 col0\" >Example</th>\n",
       "      <th id=\"T_25960_level0_col1\" class=\"col_heading level0 col1\" >Instruction</th>\n",
       "      <th id=\"T_25960_level0_col2\" class=\"col_heading level0 col2\" >Reference</th>\n",
       "      <th id=\"T_25960_level0_col3\" class=\"col_heading level0 col3\" >Baseline Output</th>\n",
       "      <th id=\"T_25960_level0_col4\" class=\"col_heading level0 col4\" >Fine-tuned Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_25960_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_25960_row0_col0\" class=\"data row0 col0\" >1</td>\n",
       "      <td id=\"T_25960_row0_col1\" class=\"data row0 col1\" >Find four highly-rated gluten-free recipes with at least 5.0 stars and under 20 minutes.</td>\n",
       "      <td id=\"T_25960_row0_col2\" class=\"data row0 col2\" >1) Cottage-Cheese Stuffed Tomatoes—10 min; 2) Nutritious Food Enhancer—15 min; 3) Chili Lime BBQ Mangoes—15 min; 4) No-Bake Low-Carb Protein Bars—5 min</td>\n",
       "      <td id=\"T_25960_row0_col3\" class=\"data row0 col3\" >[image 1] [/img][/size]</td>\n",
       "      <td id=\"T_25960_row0_col4\" class=\"data row0 col4\" >1) Pumpkin Spice Cookies With Cream—39 min; 2). Szechuan Couscous Cheese (Chickpea)—5 hr 45 sec; 3); 4.) Cinnamon Toast Crunch Bars, Fresh & Raw Vegan Honeyed Peas in a Custard Sauce.—3 hrs 35 mins.; 6): Moroccan Red Onion Quiche Bake for Gluten Free Kids! Perfectly Spiced Pineapple Chives Filled Topping The Ingredients Under 230 kcal Author : Jennifer Binder Nutrition Information Yields</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25960_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_25960_row1_col0\" class=\"data row1 col0\" >2</td>\n",
       "      <td id=\"T_25960_row1_col1\" class=\"data row1 col1\" >Find four high-protein lunchs over 34g protein in under 35 minutes.</td>\n",
       "      <td id=\"T_25960_row1_col2\" class=\"data row1 col2\" >1) Awesome Steamed Cheeseburgers!—46.0 g protein—16 min; 2) Vegetarian Sandwich with Herbed Cream Cheese and Guacamole—40.5 g protein—10 min; 3) Barbecued Buffalo Wing Dip With a Twist—195.9 g protein—25 min; 4) Aussie Tuna Summer Salad—47.4 g protein—16 min</td>\n",
       "      <td id=\"T_25960_row1_col3\" class=\"data row1 col3\" >In the first, you'll be given a 30 minute rest and then get your meal to work on 2nd Wednesday of each month for 4 weeks! This will allow it to take care not to eat too much or that morning afterwork food can come out quickly – especially when they're so hungry we don't have time (which is why this diet works). Once full again I'd recommend having 3 meals per day: 1 breakfast with pasta & potatoes; another one using breadsticks/cups</td>\n",
       "      <td id=\"T_25960_row1_col4\" class=\"data row1 col4\" >1) Feta Mackerel (Majesto)—40 min; 2—10 g carbs, 4–6 puffs.—4 mg sodium and 0% potassium.; 3). Thai Dessert for the Apple Potluck! Easy Bake With Sesame Seeds & Almonds And Goat Cheese Wraps!! Yes No Instructions Vegan or gluten free Allergy Warning — Under 119 kcal with less than 17mg sugar required.[/user]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25960_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_25960_row2_col0\" class=\"data row2 col0\" >3</td>\n",
       "      <td id=\"T_25960_row2_col1\" class=\"data row2 col1\" >Find four low-carb dinners under 12g total carbohydrates with at least 34g protein.</td>\n",
       "      <td id=\"T_25960_row2_col2\" class=\"data row2 col2\" >1) Egyptian Red Snapper in Red Pepper Mint Sauce—60.1 g protein; 2) Mustard-Grilled Scandinavian Salmon—34.9 g protein; 3) Moroccan-Spiced Tuna—53.4 g protein; 4) Melodee's Hot Wings—207.7 g protein</td>\n",
       "      <td id=\"T_25960_row2_col3\" class=\"data row2 col3\" >Dietary Approaches for Fasting: The following methods have been used in fasting or long term studies to produce a high percentage of lean muscle mass (i%E1): 1) NUTRITION & CHOICE, 2), PROTEIN, 3). For the first two diets that were considered \"fasting\", there was no need not only for blood glucose tests but also fat oxidation and lipids synthesis as well before supplementation by any foods besides fruits/proteins such As</td>\n",
       "      <td id=\"T_25960_row2_col4\" class=\"data row2 col4\" >1) Roast Chicken—494 g Protein; 2,146 min.; 3 \"Dirty Homemade Low Carb Chocolate Chip Cookies\" (Low Fat)—15 mg Fiber —5 minutes; 4). Oatmeal Crust Desserts With Cocoa Nuts and Cranberries—\"Coconut Milk Pancakes\"—27.8 G Total Carbs 1747 kcal.—1 hr 16 sec; 5.) Undercooked Pork Wings in Coconut Sandwiches Cake Sauce/Pumpkin Pie Mix,\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25960_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_25960_row3_col0\" class=\"data row3 col0\" >4</td>\n",
       "      <td id=\"T_25960_row3_col1\" class=\"data row3 col1\" >Find four highly-rated vegan recipes with at least 5.0 stars and under 30 minutes.</td>\n",
       "      <td id=\"T_25960_row3_col2\" class=\"data row3 col2\" >1) Tomato Lentil Stew—25 min; 2) Vegan Waldorf Salad—20 min; 3) Quick Elephant Ears—10 min; 4) Summer Fruit & Vegetable Medley—18 min</td>\n",
       "      <td id=\"T_25960_row3_col3\" class=\"data row3 col3\" >This post may contain links to Amazon or other partners; your purchases via these merchants are influenced by Skimlinks.\"</td>\n",
       "      <td id=\"T_25960_row3_col4\" class=\"data row3 col4\" >1) Shrimp Omelette—8 min; 2). Chunky Italian Tenderloin With Cream Cheese & Mint Sauce (Amber's Cheddar)—10 g protein, less than 24g carbs; 3.) Smoked Salmon Stews! Seasoned Fish for the Summer —35 ml sodium buffer recommended; 4): The Big Easy Dessert Cake Bake Recipe Ever Crispy? Yes No Weight in grams 25 mg carbohydrate Carbohydrate Per Serving 0–13 wt Avg Protein 763 kcal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25960_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_25960_row4_col0\" class=\"data row4 col0\" >5</td>\n",
       "      <td id=\"T_25960_row4_col1\" class=\"data row4 col1\" >Find four highly-rated vegetarian recipes with at least 4.0 stars and under 30 minutes.</td>\n",
       "      <td id=\"T_25960_row4_col2\" class=\"data row4 col2\" >1) Super-Quick Brown Rice With Asparagus, Chickpeas, and Almonds—15 min; 2) The Best Cranberry Chutney—15 min; 3) Lychees & Ice Cream (With and Without Frangelico or Amaretto—5 min; 4) New-Fashioned Apple and Raisin Slaw (From Cooking Light)—10 min</td>\n",
       "      <td id=\"T_25960_row4_col3\" class=\"data row4 col3\" >The recipe will be ready in 15 to 40 minutes, so you can also prepare it on your own as a side dish or just enjoy eating the vegan food without worrying about not being able go back for more!</td>\n",
       "      <td id=\"T_25960_row4_col4\" class=\"data row4 col4\" >1) Grilled Onion Chops—25 min; 2). Gingerbread Cabbage (Vegan, No Calorie)—20 secs; 3); Thai Vegetarian Pita Salad With Tomato Avocado & Green Peppercorn Tarragon Sauce or Blackberry Lime Juice.—30 sb total time between prepandry/dinner breakfasts;4)(Ages 11+) Vegan Chicken Breast Soup—\"6\" Mozzarella Cheese Risotto Sandwich\"—17 fds net carbs (−</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2d565564590>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " DETAILED MULTI-TURN COMPARISON\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_4f525 th {\n",
       "  text-align: center;\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_4f525 td {\n",
       "  padding: 10px;\n",
       "  border: 1px solid #ddd;\n",
       "}\n",
       "#T_4f525_row0_col0, #T_4f525_row0_col1, #T_4f525_row0_col2, #T_4f525_row0_col3, #T_4f525_row0_col4, #T_4f525_row1_col0, #T_4f525_row1_col1, #T_4f525_row1_col2, #T_4f525_row1_col3, #T_4f525_row1_col4, #T_4f525_row2_col0, #T_4f525_row2_col1, #T_4f525_row2_col2, #T_4f525_row2_col3, #T_4f525_row2_col4, #T_4f525_row3_col0, #T_4f525_row3_col1, #T_4f525_row3_col2, #T_4f525_row3_col3, #T_4f525_row3_col4, #T_4f525_row4_col0, #T_4f525_row4_col1, #T_4f525_row4_col2, #T_4f525_row4_col3, #T_4f525_row4_col4 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "  max-width: 300px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_4f525\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_4f525_level0_col0\" class=\"col_heading level0 col0\" >Example</th>\n",
       "      <th id=\"T_4f525_level0_col1\" class=\"col_heading level0 col1\" >Instruction</th>\n",
       "      <th id=\"T_4f525_level0_col2\" class=\"col_heading level0 col2\" >Reference</th>\n",
       "      <th id=\"T_4f525_level0_col3\" class=\"col_heading level0 col3\" >Baseline Output</th>\n",
       "      <th id=\"T_4f525_level0_col4\" class=\"col_heading level0 col4\" >Fine-tuned Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_4f525_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_4f525_row0_col0\" class=\"data row0 col0\" >1</td>\n",
       "      <td id=\"T_4f525_row0_col1\" class=\"data row0 col1\" >user: I need lunch ideas.\n",
       "assistant: What's your time constraint and protein goal?\n",
       "user: Under 55 minutes, at least 17g.</td>\n",
       "      <td id=\"T_4f525_row0_col2\" class=\"data row0 col2\" >1) Crispy Chicken Fingers with Spicy Honey Mustard—62.8 g protein—25 min; 2) California Avocado Monte Cristo—22.5 g protein—18 min; 3) Chicken Burrito Bundles—33.4 g protein—30 min; 4) Meatloaf Sandwiches Without the Loaf—34.2 g protein—40 min</td>\n",
       "      <td id=\"T_4f525_row0_col3\" class=\"data row0 col3\" >Where do you work for people to find out what they're getting into when their body is eating the wrong way with too much fructose in it that makes them feel sick not just physically but psychologically as well! (See my blog post here). The last thing we want from a fat person are stomachs feeling like garbage or having some sort of pain-killer effect on us after consuming so little energy because our bodies have already made up all this sugar… How about someone who isn't skinny enough yet could</td>\n",
       "      <td id=\"T_4f525_row0_col4\" class=\"data row0 col4\" >1) Chicken Soup—31 min; 2). Chunky Garlic-Roasted Peppers with Lime Dressing (Orange Juice)—26 g total carbs (−10 mg sodium); 3.) Apple Pie With Honey Salsa —18 pct in under 45 seconds; 4): Broccoli Curry Wrapped In Coconut Cream Sauce…29 mpg kcal−16 s—-0 hrs dia.—5–6 wk SDL2/4 hr.; 5)/In case you haven't noticed by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4f525_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_4f525_row1_col0\" class=\"data row1 col0\" >2</td>\n",
       "      <td id=\"T_4f525_row1_col1\" class=\"data row1 col1\" >user: Find lunch ideas.\n",
       "assistant: Are you looking for low-carb options?\n",
       "user: Yes — under 12g carbs and at least 25g protein.</td>\n",
       "      <td id=\"T_4f525_row1_col2\" class=\"data row1 col2\" >1) Crunchy Tuna Walnut Salad—25.0 g protein—4.9 g carbs; 2) Whole Foods' Tarragon Chicken Salad—26.1 g protein—8.0 g carbs; 3) Hackney's Inside-Out Burger—59.7 g protein—0.8 g carbs; 4) Appetizer or Snack Party Tray—27.7 g protein—7.2 g carbs</td>\n",
       "      <td id=\"T_4f525_row1_col3\" class=\"data row1 col3\" >Is there anything new that can help with your ketogenic diet? [sigh] And if so, what is it about carbohydrate or fat in general.? If not carbohydrates then we need to be more specific on how many calories each meal should contain. That would mean a lower number of grams per day plus lots less energy expenditure (see here ). Would carbohydrate intake have any effect when trying to achieve the same results as other foods by just eating an extra 3% gbs/day instead?? You</td>\n",
       "      <td id=\"T_4f525_row1_col4\" class=\"data row1 col4\" >1) Chicken Parmesan With Basil—28 g total carbohydrates; 2). Spicy Thai Peanut Butter Cookies (Mushroom Crab)—34 moles sodium, 17 mg potassium; 3); Asian Fried Tuna Salad with Fresh Cilantro & Spinach Omelette.—14 fts carbohydrate reduction or less than 4 min time limit; fourteen minutes.; 4.) White Chocolate Coconut Mousse Mixed Creamy Curry Fettuccine Rice Sandwich Bites Easy Roast Pork Chop in French R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4f525_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_4f525_row2_col0\" class=\"data row2 col0\" >3</td>\n",
       "      <td id=\"T_4f525_row2_col1\" class=\"data row2 col1\" >user: I need breakfast ideas.\n",
       "assistant: What's your time constraint and carbs goal?\n",
       "user: Under 55 minutes, under 24g.</td>\n",
       "      <td id=\"T_4f525_row2_col2\" class=\"data row2 col2\" >1) Campbelled Eggs—7.1 g carbs—10 min; 2) Asparagus, Mushroom and Cheese Omelet With Herbs—3.7 g carbs—15 min; 3) Corsican Omelette—4.0 g carbs—6 min; 4) Vegan Rice Pudding—11.6 g carbs—15 min</td>\n",
       "      <td id=\"T_4f525_row2_col3\" class=\"data row2 col3\" >How much does it cost to eat lunch a week in the U States compared with what you do at home (i.e., my typical day)?\n",
       "I'm on 5pm-6am EST every night during normal hours of 3AM - 2PM PST so there are no weekends off unless that is necessary for work or school! All tips used herein should be considered unofficial as these may vary by location but include any applicable information including when/where food was purchased from which store(s) please</td>\n",
       "      <td id=\"T_4f525_row2_col4\" class=\"data row2 col4\" >1) Chicken Broccoli Salad—35 min; 2). Chocolate Chip Cookie Dough Sandwich With Peanut Butter & Jelly Crust (Vegan)—25 kcal.; 3); Banana Bread Bites with Cheddar Cheese Parmesan Salsa Tenderloin Roast Beef Steak-In Soup! Easy Vegan Version 1.4 g protein in less than 12 seconds — 2520 mg sodium • 4.) Strawberry Cheesecake Cream Pie Bake Recipe for Low Carb Breakfast Pretzelies or Ketchup Cookies**</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4f525_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_4f525_row3_col0\" class=\"data row3 col0\" >4</td>\n",
       "      <td id=\"T_4f525_row3_col1\" class=\"data row3 col1\" >user: I want to make soup.\n",
       "assistant: Any dietary restrictions or sodium concerns?\n",
       "user: Yes, low sodium under 576 mg and vegetarian.</td>\n",
       "      <td id=\"T_4f525_row3_col2\" class=\"data row3 col2\" >1) Zesty Mexican Tomato Soup—519.1 mg sodium; 2) Garlic Stock for Soups—129.2 mg sodium; 3) Lebanese Adas Bis Silq (Lentil & Swisschard Soup)—218.4 mg sodium; 4) Moroccan Harira Soup—182.0 mg sodium</td>\n",
       "      <td id=\"T_4f525_row3_col3\" class=\"data row3 col3\" >What is the actual nutritional value of this product/food (i.e., calcium)? Is it more beneficial than food grade organic protein etc.? The amount you use depends on your needs for specific nutrients through blood sugar control. Are there any other ways that they are utilized throughout their development? These include a number-crunching approach involving an assessment with family members as well as medical professionals who examine each individual patient at every visit based upon how much risk he poses in terms' physical health...</td>\n",
       "      <td id=\"T_4f525_row3_col4\" class=\"data row3 col4\" >1) Garlic-Dipped Chicken—73! (28 g protein)—17 min; 2). Asian Shrimp Soup with Cucumber Cornbread Spreads & Almonds\"—35 mL water/25 minutes; 3] Keto Lemonade With Carrot Parmesan Sauce on Top—60–90 G Protein Content.—3 h 45 sec; 4); Thai Style Salsa And Feta Roasted Red Velvet Lime Dressing —0 s 25 μm glucose tolerance limit ± 1 hr BP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4f525_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_4f525_row4_col0\" class=\"data row4 col0\" >5</td>\n",
       "      <td id=\"T_4f525_row4_col1\" class=\"data row4 col1\" >user: Find lunch ideas.\n",
       "assistant: Are you looking for low-carb options?\n",
       "user: Yes — under 18g carbs and at least 34g protein.</td>\n",
       "      <td id=\"T_4f525_row4_col2\" class=\"data row4 col2\" >1) Grilled Blue Cheese Burgers—37.1 g protein—2.1 g carbs; 2) Barbecued Lobster Tails—58.6 g protein—8.3 g carbs; 3) Sandra Lee's Beef Kebabs—48.1 g protein—4.0 g carbs; 4) Any-Way-You-Want 'em Burgers—36.5 g protein—7.5 g carbs</td>\n",
       "      <td id=\"T_4f525_row4_col3\" class=\"data row4 col3\" >Have we mentioned that it's okay to eat less than 30% of your daily calories from carbohydrates in the morning, but if not eating a lot then don't have enough time on my end or I'll be late. Can someone tell me more about this? Email [email protected] If all else fails please send us an email with comments explaining why they're bad choices</td>\n",
       "      <td id=\"T_4f525_row4_col4\" class=\"data row4 col4\" >1) Broccoli Shrimp—38 g Protein; 2 ) Pineapple Crisps With Cream Sauce (Pine Barbecue)—32 mg Carbohydrate, 17 min.; 3/4 Cup Chicken Breast Brunch with Cabbage And Basil Soup Mixing Lime Juice For Two Spices! Gluten Free & Low Cal Diet!\"Content Warning–Reduced sodium is recommended.–564 kcal.—037 s.\"Vegetarian\"--65% less saturated fat than average intake of 2098mg cholesterol</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2d5656d4bd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import json \n",
    "\n",
    "def compare_outputs(baseline_file, finetuned_file, num_examples=10):\n",
    "    baseline_data = []\n",
    "    finetuned_data = []\n",
    "\n",
    "    with open(baseline_file, \"r\", encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            baseline_data.append(json.loads(line))\n",
    "\n",
    "    with open(finetuned_file, \"r\", encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            finetuned_data.append(json.loads(line))\n",
    "\n",
    "    comparisons = []\n",
    "    for i in range(min(num_examples, len(baseline_data), len(finetuned_data))):\n",
    "        baseline = baseline_data[i]\n",
    "        finetuned = finetuned_data[i]\n",
    "        \n",
    "        # Handle single-turn format\n",
    "        if \"instruction\" in baseline:\n",
    "            instruction = baseline[\"instruction\"]\n",
    "            if baseline.get(\"input\"):\n",
    "                instruction += f\"\\nInput: {baseline['input']}\"\n",
    "        # Handle multi-turn format\n",
    "        else:\n",
    "            messages = baseline[\"messages\"]\n",
    "            instruction = \"\\n\".join([f\"{m['role']}: {m['content']}\" for m in messages[:-1]])\n",
    "        \n",
    "        comparisons.append({\n",
    "            \"Example\": i + 1,\n",
    "            \"Instruction\": instruction,\n",
    "            \"Reference\": baseline[\"reference_output\"],\n",
    "            \"Baseline Output\": baseline[\"model_output\"],\n",
    "            \"Fine-tuned Output\": finetuned[\"model_output\"]\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(comparisons)\n",
    "    \n",
    "    styled_df = df.style.set_properties(**{\n",
    "        'text-align': 'left',\n",
    "        'white-space': 'pre-wrap',\n",
    "        'word-wrap': 'break-word',\n",
    "        'max-width': '300px'\n",
    "    }).set_table_styles([\n",
    "        {'selector': 'th', 'props': [('text-align', 'center'), ('font-weight', 'bold')]},\\\n",
    "        {'selector': 'td', 'props': [('padding', '10px'), ('border', '1px solid #ddd')]}\n",
    "    ])\n",
    "    \n",
    "    return styled_df\n",
    "\n",
    "print(\"\\n\\n DETAILED SINGLE-TURN COMPARISON\\n\")\n",
    "display(compare_outputs(\n",
    "    \"baseline_single_turn_outputs.jsonl\",\n",
    "    \"combined_finetuned_single_turn_outputs.jsonl\",\n",
    "    num_examples=5\n",
    "))\n",
    "\n",
    "print(\"\\n\\n DETAILED MULTI-TURN COMPARISON\\n\")\n",
    "display(compare_outputs(\n",
    "    \"baseline_multi_turn_outputs.jsonl\",\n",
    "    \"combined_finetuned_multi_turn_outputs.jsonl\",\n",
    "    num_examples=5\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a07cbb12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EVALUATING SINGLE-TURN ===\n",
      "Baseline   - BLEU: 0.019 (10/10 examples)\n",
      "Fine-tuned - BLEU: 0.077 (10/10 examples)\n",
      "Improvement: +310.2%\n",
      "\n",
      "=== EVALUATING MULTI-TURN ===\n",
      "Baseline   - BLEU: 0.010 (10/10 examples)\n",
      "Fine-tuned - BLEU: 0.062 (10/10 examples)\n",
      "Improvement: +496.3%\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from typing import Dict\n",
    "\n",
    "class SimpleEvaluator:\n",
    "    \n",
    "    def calculate_bleu(self, reference: str, hypothesis: str) -> float:\n",
    "        \"\"\"Simple unigram BLEU score\"\"\"\n",
    "        ref_tokens = reference.lower().split()\n",
    "        hyp_tokens = hypothesis.lower().split()\n",
    "        \n",
    "        if not hyp_tokens:\n",
    "            return 0.0\n",
    "        \n",
    "        ref_counts = Counter(ref_tokens)\n",
    "        hyp_counts = Counter(hyp_tokens)\n",
    "        \n",
    "        # Count matches\n",
    "        matches = sum((hyp_counts & ref_counts).values())\n",
    "        precision = matches / len(hyp_tokens) if hyp_tokens else 0.0\n",
    "        \n",
    "        # Brevity penalty\n",
    "        bp = min(1.0, len(hyp_tokens) / len(ref_tokens)) if ref_tokens else 0.0\n",
    "        \n",
    "        return precision * bp\n",
    "    \n",
    "    def evaluate_file(self, output_file: str, is_multi_turn: bool = False) -> Dict:\n",
    "        \"\"\"Evaluate all examples in a file\"\"\"\n",
    "        bleu_scores = []\n",
    "        total = 0\n",
    "        valid = 0\n",
    "        \n",
    "        with open(output_file, 'r') as f:\n",
    "            for line in f:\n",
    "                example = json.loads(line)\n",
    "                total += 1\n",
    "                model_output = example.get('model_output', '').strip()\n",
    "        \n",
    "                reference_output = example.get('reference_output', '').strip()\n",
    "                \n",
    "                if not model_output or not reference_output:\n",
    "                    continue\n",
    "                \n",
    "                valid += 1\n",
    "                bleu = self.calculate_bleu(reference_output, model_output)\n",
    "                bleu_scores.append(bleu)\n",
    "        \n",
    "        return {\n",
    "            'total_examples': total,\n",
    "            'valid_outputs': valid,\n",
    "            'avg_bleu': sum(bleu_scores) / len(bleu_scores) if bleu_scores else 0.0\n",
    "        }\n",
    "\n",
    "def compare_baseline_vs_finetuned():\n",
    "    \"\"\"Compare baseline and fine-tuned model outputs\"\"\"\n",
    "    evaluator = SimpleEvaluator()\n",
    "    \n",
    "    print(\"=== EVALUATING SINGLE-TURN ===\")\n",
    "    baseline_st = evaluator.evaluate_file('baseline_single_turn_outputs.jsonl')\n",
    "    finetuned_st = evaluator.evaluate_file('combined_finetuned_single_turn_outputs.jsonl')\n",
    "    \n",
    "    print(f\"Baseline   - BLEU: {baseline_st['avg_bleu']:.3f} ({baseline_st['valid_outputs']}/{baseline_st['total_examples']} examples)\")\n",
    "    print(f\"Fine-tuned - BLEU: {finetuned_st['avg_bleu']:.3f} ({finetuned_st['valid_outputs']}/{finetuned_st['total_examples']} examples)\")\n",
    "    \n",
    "    if baseline_st['avg_bleu'] > 0:\n",
    "        st_improvement = ((finetuned_st['avg_bleu'] - baseline_st['avg_bleu']) / baseline_st['avg_bleu']) * 100\n",
    "        print(f\"Improvement: {st_improvement:+.1f}%\")\n",
    "    \n",
    "    print(\"\\n=== EVALUATING MULTI-TURN ===\")\n",
    "    baseline_mt = evaluator.evaluate_file('baseline_multi_turn_outputs.jsonl')\n",
    "    finetuned_mt = evaluator.evaluate_file('combined_finetuned_multi_turn_outputs.jsonl')\n",
    "    \n",
    "    print(f\"Baseline   - BLEU: {baseline_mt['avg_bleu']:.3f} ({baseline_mt['valid_outputs']}/{baseline_mt['total_examples']} examples)\")\n",
    "    print(f\"Fine-tuned - BLEU: {finetuned_mt['avg_bleu']:.3f} ({finetuned_mt['valid_outputs']}/{finetuned_mt['total_examples']} examples)\")\n",
    "    \n",
    "    if baseline_mt['avg_bleu'] > 0:\n",
    "        mt_improvement = ((finetuned_mt['avg_bleu'] - baseline_mt['avg_bleu']) / baseline_mt['avg_bleu']) * 100\n",
    "        print(f\"Improvement: {mt_improvement:+.1f}%\")\n",
    "\n",
    "compare_baseline_vs_finetuned()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
